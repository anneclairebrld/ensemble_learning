{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Text classification with Rakuten France Product Data\n",
    "### Part 1: Produce the tfidf matrices\n",
    "Re-using the code provided in lab 2 we compute the tfidf matrix for each product designation.\n",
    "The data is then saved to a pickle file (both the dataframe with designations pre-processed and the tfidf matrices). <b> Skip first part if the data is already saved in pickles and run the second part directly, loading the data from pickle <b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle ## so that we do not have to run thetfidf all the time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data in \n",
    "X_train_df = pd.read_csv('./data/X_train_update.csv')\n",
    "Y_train_df = pd.read_csv('./data/Y_train.csv') # note to self -> rename the file\n",
    "\n",
    "# rename columns to be readable\n",
    "X_train_df = X_train_df.rename(columns = {'Unnamed: 0':'id'})\n",
    "Y_train_df = Y_train_df.rename(columns = {'Unnamed: 0':'id'})\n",
    "\n",
    "#disregard columns that are not needed\n",
    "X_train_df = X_train_df.filter(['id', 'designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        designation\n",
       "0   0  Olivia: Personalisiertes Notizbuch / 150 Seite...\n",
       "1   1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...\n",
       "2   2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...\n",
       "3   3  Peluche Donald - Europe - Disneyland 2000 (Mar...\n",
       "4   4                               La Guerre Des Tuques"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display data\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prdtypecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  prdtypecode\n",
       "0   0           10\n",
       "1   1         2280\n",
       "2   2           50\n",
       "3   3         1280\n",
       "4   4         2705"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display data\n",
    "Y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions defined in lab 2\n",
    "\n",
    "def normalize_accent(string):\n",
    "    string = string.replace('á', 'a')\n",
    "    string = string.replace('â', 'a')\n",
    "\n",
    "    string = string.replace('é', 'e')\n",
    "    string = string.replace('è', 'e')\n",
    "    string = string.replace('ê', 'e')\n",
    "    string = string.replace('ë', 'e')\n",
    "\n",
    "    string = string.replace('î', 'i')\n",
    "    string = string.replace('ï', 'i')\n",
    "\n",
    "    string = string.replace('ö', 'o')\n",
    "    string = string.replace('ô', 'o')\n",
    "    string = string.replace('ò', 'o')\n",
    "    string = string.replace('ó', 'o')\n",
    "\n",
    "    string = string.replace('ù', 'u')\n",
    "    string = string.replace('û', 'u')\n",
    "    string = string.replace('ü', 'u')\n",
    "\n",
    "    string = string.replace('ç', 'c')\n",
    "    \n",
    "    return string\n",
    "\n",
    "\n",
    "\n",
    "def raw_to_tokens(raw_string, spacy_nlp):\n",
    "    # Write code for lower-casing\n",
    "    string = raw_string.lower()\n",
    "    \n",
    "    # Write code to normalize the accents\n",
    "    string = normalize_accent(string)\n",
    "        \n",
    "    # Write code to tokenize\n",
    "    spacy_tokens = spacy_nlp(string)\n",
    "        \n",
    "    # Write code to remove punctuation tokens and create string tokens\n",
    "    string_tokens = [token.orth_ for token in spacy_tokens if not token.is_punct if not token.is_stop]\n",
    "    \n",
    "    # Write code to join the tokens back into a single string\n",
    "    clean_string = \" \".join(string_tokens)\n",
    "    \n",
    "    return clean_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load('fr')\n",
    "\n",
    "# clean data\n",
    "X_train_df['designation'] = X_train_df.designation.apply(lambda row: raw_to_tokens(row, spacy_nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the tfidf matrix \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(X_train.designation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to pickle\n",
    "X_train_df.to_pickle('X_train_df.pickle')\n",
    "\n",
    "# save tfidf to pickle \n",
    "pickle.dump(X_tfidf, open('X_tfidf.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>olivia personalisiertes notizbuch 150 seiten p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>journal arts n° 133 28/09/2001 art marche salo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>grand stylet ergonomique bleu gamepad nintendo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>peluche donald europe disneyland 2000 marionne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>guerre tuques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        designation\n",
       "0   0  olivia personalisiertes notizbuch 150 seiten p...\n",
       "1   1  journal arts n° 133 28/09/2001 art marche salo...\n",
       "2   2  grand stylet ergonomique bleu gamepad nintendo...\n",
       "3   3  peluche donald europe disneyland 2000 marionne...\n",
       "4   4                                      guerre tuques"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check final data format\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Model testing and comparisons\n",
    "If only starting here load data from pickle i.e. set load to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global imports\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "load_pickle_data = False\n",
    "if load_pickle_data:\n",
    "    X_train_df = pd.read_pickle('X_train_df.pickle')\n",
    "    X_tfidf = pickle.load(X_tfidf, open('X_tfidf.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67932, 83370)\n",
      "(67932,)\n",
      "(16984, 83370)\n",
      "(16984,)\n"
     ]
    }
   ],
   "source": [
    "## Split data to do cross validation\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf,\n",
    "                                                    Y_train_df.prdtypecode, \n",
    "                                                   test_size = 0.2, \n",
    "                                                   random_state = 42)\n",
    "\n",
    "# check shapes\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model:  RandomForest\n",
      "0.6388235838120959\n",
      "[[ 120    1    0    0    1    1    0    2    0    6    0    0    0    2\n",
      "     2    0    4    1  154   47    0    4    0  251    0   16    0]\n",
      " [  29  182   24    0    5    7    0    0    2    2    0    0    0    0\n",
      "     0    0    3    0   27    6   15    5    1  205    0    6    2]\n",
      " [   2    4  182    7    7    5    0    1    0   16    0    7    1    6\n",
      "     1    0    4    0    3    2   14    4    0   91    0    0    0]\n",
      " [   0    2    8  131    0    0    0    0    0    1    0    0    0    0\n",
      "     0    0    0    0    0    0   10    0    0    9    0    0    0]\n",
      " [  10    8    0    0  302   15    2    7    0    6    0    1    5    2\n",
      "     0    0    2    1   27   16    2    4    0  129    0    0    0]\n",
      " [   3    1    0    0    3  638    0    0    1    3    0    0    0    0\n",
      "     0    0    0    0   18    4    0    1    0  113    0    1    0]\n",
      " [   9    1    0    0   11    4   35    6    2    1    1    0    0    3\n",
      "     0    0    0    0    8    2    0    2    0   61    0    0    0]\n",
      " [   5   13    3    1   45   10    0  460   22  142    3    8    4   11\n",
      "     4    0   20    2   15   16    2    3    3  168    0    1    0]\n",
      " [  14   12    2    0    8   17    6   90   74    8    1    1    1    3\n",
      "     1    0    3    3   25    7    4    6    0  136    0    2    0]\n",
      " [   2    2    0    0    0    1    0    3    0  842    0    0    0    1\n",
      "     0    0    1    0    6    1    0    6    0  109    0    0    0]\n",
      " [   0    0    0    0    0    0    0    3    1    2  114    0    0    4\n",
      "     1    0    2    0    0    1    0    9    0   32    0    0    0]\n",
      " [   1    0    0    0    2    0    0   45    0    5    0  285    5    7\n",
      "     2    0    6    1    5    7    1    5    5  124    0    0    1]\n",
      " [   2    2    1    0    0    3    0   40    0    5    1    0  281   27\n",
      "    30    0   35    1    8   12    0    3    0  221    0    0    0]\n",
      " [   3    1    0    0    1    0    0    8    0    4    0    0    6  807\n",
      "    23    0   43    0    3    6    0   13   11   82    2    0    0]\n",
      " [   0    0    0    0    0    0    0    3    1    0    0    0    2   20\n",
      "   733    0   26    1    1    6    0    0    1   47    0    0    0]\n",
      " [   0    0    0    0    0    1    0    0    0    0    0    0    0    0\n",
      "     0   20    0    1    3    6    0    0    1  105    0    0    0]\n",
      " [   1    1    0    0    4    4    0   13    0    3    0    3    6   60\n",
      "    24    0  742    0    7    4    0   10    3  140    4    0    0]\n",
      " [   0    0    0    0    0    0    0    4    0    1    0    0    0    6\n",
      "     6    0    6   99    1    4    0    2    0   41    0    0    0]\n",
      " [   8    1    0    0    0    5    0    1    0    1    0    0    0    3\n",
      "     2    0    1    0  689   31    1    2    1  191    0    5    0]\n",
      " [   9    0    0    0    0    4    0    1    0    0    0    0    0    4\n",
      "     0    0    1    1  142  643    0    4    0  172    0    5    0]\n",
      " [   2    6   10    3    4    9    0    0    1    2    0    0    0    0\n",
      "     0    0    2    0    6    9  205    1    0   46    0    0    0]\n",
      " [   2    2    0    0    1   10    0    1    0    1    0    0    0   11\n",
      "     4    0   10    0    5   11    0  781    0  150    2    0    0]\n",
      " [   1    0    0    0    1    1    0    5    0    1    0    1    1   59\n",
      "    13    1   26    2    9    7    0    4  181  146    3    0    0]\n",
      " [   0    1    0    0    0    1    0    1    0    0    0    0    1    2\n",
      "     0    0    7    0    2    0    0    4    0 2028    0    0    0]\n",
      " [   0    0    0    0    0    2    0    1    0    4    0    2    5   17\n",
      "     2    0   16    0    8    5    0   20   13  225  205    0    0]\n",
      " [   3    0    0    0    1    1    0    4    0    0    0    0    3    2\n",
      "     0    0    2    0  175   33    1    2    0  237    0   53    0]\n",
      " [   0    0    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    2    0    0  186]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import  f1_score, confusion_matrix\n",
    "    \n",
    "# Grab all models\n",
    "models = [RandomForestClassifier(max_depth = 75)] #, \n",
    "              #AdaBoostClassifier(random_state=42, learning_rate= 0.1), \n",
    "          #BaggingClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier()] \n",
    "model_names = ['RandomForest']#, 'AdaBoost', 'Bagging', 'Gradient_boosting', 'Decision_tree'] \n",
    "f1_scores = list()\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    print('Running model: ', model_names[idx])\n",
    "    \n",
    "    # fit and predict\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    \n",
    "    f1_scores.append(f1_score(y_test, test_pred, average='weighted'))\n",
    "    print(f1_scores[idx])\n",
    "    print(confusion_matrix(y_test,test_pred))\n",
    "\n",
    "d = {'Modelling Algo':model_names,'f1_score':f1_scores} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
